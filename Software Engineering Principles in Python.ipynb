{"cells":[{"source":"# Software Engineering Principles in Python","metadata":{},"id":"20c73b4c-626a-4674-b2ca-0f4c47f60628","cell_type":"markdown"},{"source":"## Python modularity in the wild\nIn the slides, we covered 3 ways that you can write modular code with Python: packages, classes, and methods. For reference, you can see the example code we reviewed below.\n\n# Import the pandas PACKAGE\nimport pandas as pd\n\n# Create some example data\ndata = {'x': [1, 2, 3, 4], \n        'y': [20.1, 62.5, 34.8, 42.7]}\n\n# Create a dataframe CLASS object\ndf = pd.DataFrame(data)\n\n# Use the plot METHOD\ndf.plot('x', 'y')\nIn this exercise, you'll utilize a class & a method from the popular package numpy.","metadata":{},"cell_type":"markdown","id":"431f862f-7bf2-437d-82ac-8af069630978"},{"source":"# import the numpy package\nimport numpy as np\n\n# create an array class object\narr = np.array([8, 6, 7, 5, 3, 0, 9])\n\n# use the sort method\narr.sort()\n\n# print the sorted array\nprint(arr)","metadata":{},"cell_type":"code","id":"90f1ac60-34f0-4a07-b4aa-e8de8b914495","execution_count":null,"outputs":[]},{"source":"## Leveraging documentation\nWhen writing code for Data Science, it's inevitable that you'll need to install and use someone else's code. You'll quickly learn that using someone else's code is much more pleasant when they use good software engineering practices. In particular, good documentation makes the right way to call a function obvious. In this exercise you'll use python's help() method to view a function's documentation so you can determine how to correctly call a new method.\n\nThe list words has been loaded in your session.","metadata":{},"cell_type":"markdown","id":"25769b78-46f2-4ed4-b400-fc9496e51ce6"},{"source":"# load the Counter function into our environment\nfrom collections import Counter\n\n# View the documentation for Counter.most_common\nhelp(Counter.most_common)\n\n# use Counter to find the top 5 most common words\ntop_5_words = Counter(words).most_common(5)\n\n# display the top 5 most common words\nprint(top_5_words)\n","metadata":{},"cell_type":"code","id":"8346accd-5d08-4680-ae53-c522bce74586","execution_count":null,"outputs":[]},{"source":"## Using pycodestyle\nWe saw earlier that pycodestyle can be run from the command line to check a file for PEP 8 compliance. Sometimes it's useful to run this kind of check from a Python script.\n\nIn this exercise, you'll use pycodestyle's StyleGuide class to check multiple files for PEP 8 compliance. Both files accomplish the same task, but they differ greatly in formatting and readability. You can view the contents of the files by following their links below.","metadata":{},"cell_type":"markdown","id":"e446eb3c-9cc9-4e22-86e1-5823fb806b79"},{"source":"# Import needed package\nimport pycodestyle\n\n# Create a StyleGuide instance\nstyle_checker = pycodestyle.StyleGuide()\n\n# Run PEP 8 check on multiple files\nresult = style_checker.check_files(['nay_pep8.py', 'yay_pep8.py'])\n\n# Print result of PEP 8 style check\nprint(result.messages)\n","metadata":{},"cell_type":"code","id":"66955221-86f7-479b-b9f8-46ab0db229a1","execution_count":null,"outputs":[]},{"source":"## Conforming to PEP 8\nAs we've covered, there are tools available to check if your code conforms to the PEP 8 guidelines. One possible way to stay compliant is to use an IDE that warns you when you accidentally stray from the style guide. Another way to check code is to use the pycodestyle package.\n\nThe results below show the output of running pycodestyle check against the code shown in your editor. The leading number in each line shows how many occurrences there were of that particular violation.\n\nmy_script.py:2:2:  E225 missing whitespace around operator\nmy_script.py:2:7:  E231 missing whitespace after ','\nmy_script.py:2:9:  E231 missing whitespace after ','\nmy_script.py:5:7:  E201 whitespace after '('\nmy_script.py:5:11: E202 whitespace before ')'","metadata":{},"cell_type":"markdown","id":"dc7cd6d6-3a9b-441b-9c94-8f4a66879ca2"},{"source":"# Assign data to x\nx = [8, 3, 4]\n\n# Print the data\nprint(x)","metadata":{},"cell_type":"code","id":"b764de87-0d5a-4ecc-969a-574d405a3bb0","execution_count":null,"outputs":[]},{"source":"## PEP 8 in documentation\nSo far we've focused on how PEP 8 affects functional pieces of code. There are also rules to help make comments and documentation more readable. In this exercise, you'll be fixing various types of comments to be PEP 8 compliant.\n\nThe result of a pycodestyle style check on the code can be seen below.\n\nmy_script.py:2:15: E261 at least two spaces before inline comment\nmy_script.py:5:16: E262 inline comment should start with '# '\nmy_script.py:11:1: E265 block comment should start with '# '\nmy_script.py:13:2: E114 indentation is not a multiple of four (comment)\nmy_script.py:13:2: E116 unexpected indentation (comment)","metadata":{},"cell_type":"markdown","id":"04bac6c1-7cbf-476c-8ace-44e0998295c5"},{"source":"def print_phrase(phrase, polite=True, shout=False):\n    if polite:  # It's generally polite to say please\n        phrase = 'Please' + phrase\n\n    if shout:  # All caps looks like a written shout\n        phrase = phrase.upper() + '!!'\n\n    print(phrase)\n\n\n# Politely ask for help\nprint_phrase('help me', polite=True)\n# Shout about a discovery\nprint_phrase('eureka', shout=True)\n","metadata":{},"cell_type":"code","id":"be68cd48-b19e-4c38-ae87-b92b8270f736","execution_count":null,"outputs":[]},{"source":"## Naming packages\nWe covered the PEP 8 guidelines for naming packages. In this exercise, you'll use that knowledge to identify a package following the requirements.\n\nFor additional reference, you can view the PEP 8 section on package naming here","metadata":{},"cell_type":"markdown","id":"f08c12a8-883c-4f8c-b183-ccb3ae155d8d"},{"source":"# Import the package with a name that follows PEP 8\nimport text_analyzer\nimport textAnalyzer\nimport TextAnalyzer\nimport __text_analyzer__\n","metadata":{},"cell_type":"code","id":"8525dc22-963d-4863-85f3-3e51e310a76a","execution_count":null,"outputs":[]},{"source":"## Recognizing packages\nThe structure of your directory tree is printed below. You'll be working in the file my_script.py that you can see in the tree.\n\nrecognizing_packages\n├── MY_PACKAGE\n│&nbsp;&nbsp; └── _init_.py\n├── package\n│&nbsp;&nbsp; └── __init__.py\n├── package_py\n│&nbsp;&nbsp; └── __init__\n│&nbsp;&nbsp;     └── __init__.py\n├── py_package\n│&nbsp;&nbsp; └── __init__.py\n├── pyackage\n│&nbsp;&nbsp; └── init.py\n└── my_script.py","metadata":{},"cell_type":"markdown","id":"a929e730-d8a8-41a1-aa8a-0d217144e37e"},{"source":"# Import local packages\nimport py_package\nimport package\n\n# View the help for each package\nhelp(py_package)\nhelp(package)\n","metadata":{},"cell_type":"code","id":"916d1fd9-d9b4-44d6-9694-03af59ead6a4","execution_count":null,"outputs":[]},{"source":"## Adding functionality to your package\nThanks to your work before, you already have a skeleton for your python package. In this exercise, you will work to define the functions needed for a text analysis of word usage.\n\nIn the file counter_utils.py, you will write 2 functions to be a part of your package: plot_counter and sum_counters. The structure of your package can be seen in the tree below. For the coding portions of this exercise, you will be working in the file counter_utils.py.\n\ntext_analyzer\n├── __init__.py\n└── counter_utils.py","metadata":{},"cell_type":"markdown","id":"355028ed-7c60-427a-9343-01e4baab0f3d"},{"source":"# Import needed functionality\nfrom collections import Counter\n\ndef plot_counter(counter, n_most_common=5):\n  # Subset the n_most_common items from the input counter\n  top_items = counter.most_common(n_most_common)\n  # Plot `top_items`\n  plot_counter_most_common(top_items)\n","metadata":{},"cell_type":"code","id":"df41db9e-1546-4247-80fb-a888a01f1aaa","execution_count":null,"outputs":[]},{"source":"# Import needed functionality\nfrom collections import Counter\n\ndef sum_counters(counters):\n  # Sum the inputted counters\n  return sum(counters, Counter())\n","metadata":{},"cell_type":"code","id":"b574f8e3-c960-432b-85e0-8ea16f269924","execution_count":null,"outputs":[]},{"source":"## Using your package's new functionality\nYou've now created some great functionality for text analysis to your package. In this exercise, you'll leverage your package to analyze some tweets written by DataCamp & DataCamp users.\n\nThe object word_counts is loaded into your environment. It contains a list of Counter objects that contain word counts from a sample of DataCamp tweets.\n\nThe structure you've created can be seen in the tree below. You'll be working in my_script.py.\n\nworking_dir\n├── text_analyzer\n│    ├── __init__.py\n│    ├── counter_utils.py\n└── my_script.py","metadata":{},"cell_type":"markdown","id":"192ff297-c0d8-43de-af4a-5dd22fa85f0d"},{"source":"# Import local package\nimport text_analyzer\n\n# Sum word_counts using sum_counters from text_analyzer\nword_count_totals = text_analyzer.sum_counters(word_counts)\n\n# Plot word_count_totals using plot_counter from text_analyzer\ntext_analyzer.plot_counter(word_count_totals)","metadata":{},"cell_type":"code","id":"730e9585-75a3-44a7-9a2f-7542997343b5","execution_count":null,"outputs":[]},{"source":"## Writing requirements.txt\nWe covered how having a requirements.txt file can help your package be more portable by allowing your users to easily recreate its intended environment. In this exercise, you will be writing the contents of a requirements file to a python variable.\n\nNote, in practice, the code you write in this exercise would be written to it's own txt file instead of a variable in your python session.","metadata":{},"cell_type":"markdown","id":"fa0c1b9a-7bcf-404f-8fc4-cf3b9b4c1f3c"},{"source":"requirements = \"\"\"\nmatplotlib>=3.0.0\nnumpy==1.15.4\npandas<=0.22.0\npycodestyle\n\"\"\"","metadata":{},"cell_type":"code","id":"12eff0e5-9219-422c-8ca4-5a6c7cd3509d","execution_count":null,"outputs":[]},{"source":"## Creating setup.py\nIn order to make your package installable by pip you need to create a setup.py file. In this exercise you will create this file for the text_analyzer package you've been building.","metadata":{},"cell_type":"markdown","id":"fb3cf598-0f2c-4e78-9fdb-c31af8c1121d"},{"source":"# Import needed function from setuptools\nfrom setuptools import setup\n\n# Create proper setup to be used by pip\nsetup(name='text_analyzer',\n      version='0.0.1',\n      description='Perform and visualize a text anaylsis.',\n      author='username',\n      packages=['text_analyzer'])","metadata":{},"cell_type":"code","id":"c54fcd55-189e-44fc-b21b-466273524a9c","execution_count":null,"outputs":[]},{"source":"## Listing requirements in setup.py\nWe created a setup.py file earlier, but we forgot to list our dependency on matplotlib in the install_requires argument. In this exercise you will practice listing your version specific dependencies by correcting the setup.py you previously wrote for your text_analyzer package.","metadata":{},"cell_type":"markdown","id":"b40feb57-1aa9-4479-a99b-a0ddf48c926a"},{"source":"# Import needed function from setuptools\nfrom ____ import setup\n\n# Create proper setup to be used by pip\nsetup(name='text_analyzer',\n      version='0.0.1',\n      description='Perform and visualize a text anaylsis.',\n      author='____',\n      packages=['text_analyzer'],\n      install_requires=['____'])\n","metadata":{},"cell_type":"code","id":"d76a6962-37c3-4095-a07e-6a0880bd6c90","execution_count":null,"outputs":[]},{"source":"## Writing a class for your package\nWe've covered how classes can be written in Python. In this exercise, you'll be creating the beginnings of a Document class that will be a foundation for text analysis in your package. Once the class is written you will modify your package's __init__.py file to make it easily accessible by your users.\n\nBelow is the structure of where you'll be working.\n\nworking_dir\n├── text_analyzer\n│    ├── __init__.py\n│    ├── counter_utils.py\n│    ├── document.py\n└── my_script.py","metadata":{},"cell_type":"markdown","id":"a1203d9a-31ac-4911-a6af-9916e07ae75d"},{"source":"# Define Document class\nclass Document:\n    \"\"\"A class for text analysis\n    \n    :param text: string of text to be analyzed\n    :ivar text: string of text to be analyzed; set by `text` parameter\n    \"\"\"\n    # Method to create a new instance of MyClass\n    def __init__(self, text):\n        # Store text parameter to the text attribute\n        self.text = text\n","metadata":{},"cell_type":"code","id":"f19a195d-c7f9-41df-91e7-6e621a7f200f","execution_count":null,"outputs":[]},{"source":"## Using your package's class\nYou just wrote the beginnings of a Document class that you'll build upon to perform text analysis. In this exercise, you'll test out its current functionality of storing text.\n\nBelow is the document tree that you've built up so far when developing your package. You'll be working in my_script.py.\n\nworking_dir\n├── text_analyzer\n│    ├── __init__.py\n│    ├── counter_utils.py\n│    ├── document.py\n└── my_script.py","metadata":{},"cell_type":"markdown","id":"d1731e76-0f06-4aae-bb61-4d20836db04d"},{"source":"# Import custom text_analyzer package\nimport text_analyzer\n\n# Create an instance of Document with datacamp_tweet\nmy_document = text_analyzer.Document(text=datacamp_tweet)\n\n# Print the text attribute of the Document instance\nprint(my_document.text)\n","metadata":{},"cell_type":"code","id":"e366d792-63b2-4b80-8deb-422cc813afbb","execution_count":null,"outputs":[]},{"source":"## Writing a non-public method\nIn the lesson, we covered how to add functionality to classes using non-public methods. By defining methods as non-public you're signifying to the user that the method is only to be used inside the package.\n\nIn this exercise, you will define a non-public method that will be leveraged by your class to count words.","metadata":{},"cell_type":"markdown","id":"8ab7e5f7-134b-4d92-a010-d02522791001"},{"source":"class Document:\n  def __init__(self, text):\n    self.text = text\n    # pre tokenize the document with non-public tokenize method\n    self.tokens = self._tokenize()\n    # pre tokenize the document with non-public count_words\n    self.word_counts = self._count_words()\n\n  def _tokenize(self):\n    return tokenize(self.text)\n\t\n  # non-public method to tally document's word counts with Counter\n  def _count_words(self):\n    return Counter(self.tokens)","metadata":{},"cell_type":"code","id":"46638568-d02b-40ac-9c1c-d000b4c18cb0","execution_count":null,"outputs":[]},{"source":"## Using your class's functionality\nYou've now added additional functionality to your Document class's __init__ method that automatically processes text for your users. In this exercise, you'll act as one of those users to see the benefits of your hard work.\n\nThe Document class (copied below) has been loaded into your environment (complete with your new updates).\n\nclass Document:\n  def __init__(self, text):\n    self.text = text\n    # pre tokenize the document with non-public tokenize method\n    self.tokens = self._tokenize()\n    # pre tokenize the document with non-public count_words\n    self.word_counts = self._count_words()\n\n  def _tokenize(self):\n    return tokenize(self.text)\n\n  # non-public method to tally document's word counts with Counter\n  def _count_words(self):\n    return Counter(self.tokens)\n","metadata":{},"cell_type":"markdown","id":"c79cb17b-69e0-4971-a59d-7c4f702b07cb"},{"source":"# create a new document instance from datacamp_tweets\ndatacamp_doc = Document(datacamp_tweets)\n\n# print the first 5 tokens from datacamp_doc\nprint(datacamp_doc.tokens[:5])\n\n# print the top 5 most used words in datacamp_doc\nprint(datacamp_doc.word_counts.most_common(5))\n","metadata":{},"cell_type":"code","id":"36e36459-0778-498a-ad6c-5dacf54e96ee","execution_count":null,"outputs":[]},{"source":"## Using inheritance to create a class\nYou've previously written a Document class for text analysis, but your NLP project will now have a focus on Social Media data. Your general Document class might be useful later so it's best not destroy it while your focus shifts to tweets.\n\nInstead of copy-pasting the already written functionality, you will use the principles of 'DRY' and inheritance to quickly create your new SocialMedia class.","metadata":{},"cell_type":"markdown","id":"57877c72-6463-4f1f-b437-f341212abbd8"},{"source":"# Define a SocialMedia class that is a child of the `Document class`\nclass SocialMedia(Document):\n    def __init__(self, text):\n        Document.__init__(self, text)\n","metadata":{},"cell_type":"code","id":"ca0097c9-bde6-4c42-87aa-2b81da391f7d","execution_count":null,"outputs":[]},{"source":"## Adding functionality to a child class\nYou've just written a SocialMedia class that inherits functionality from Document. As of now, the SocialMedia class doesn't have any functionality different from Document. In this exercise, you will build features into SocialMedia to specialize it for use with Social Media data.\n\nFor reference, the definition of Document can be seen below.\n\nclass Document:\n    # Initialize a new Document instance\n    def __init__(self, text):\n        self.text = text\n        # Pre tokenize the document with non-public tokenize method\n        self.tokens = self._tokenize()\n        # Pre tokenize the document with non-public count_words\n        self.word_counts = self._count_words()\n\n    def _tokenize(self):\n        return tokenize(self.text)\n\n    # Non-public method to tally document's word counts\n    def _count_words(self):\n        # Use collections.Counter to count the document's tokens\n        return Counter(self.tokens)","metadata":{},"cell_type":"markdown","id":"b1f377fe-266e-4440-bdbe-14a4511fc2ba"},{"source":"# Define a SocialMedia class that is a child of the `Document class`\nclass SocialMedia(Document):\n    def __init__(self, text):\n        Document.__init__(self, text)\n        self.hashtag_counts = self._count_hashtags()\n        self.mention_counts = self._count_mentions()\n        \n    def _count_hashtags(self):\n        # Filter attribute so only words starting with '#' remain\n        return filter_word_counts(self.word_counts, first_char='#')\n    \n    def _count_mentions(self):\n        # Filter attribute so only words starting with '@' remain\n        return filter_word_counts(self.word_counts, first_char='@')","metadata":{},"cell_type":"code","id":"2d47eff4-4466-49ba-bd47-024ed34de909","execution_count":null,"outputs":[]},{"source":"## Using your child class\nThanks to the power of inheritance you were able to create a feature-rich, SocialMedia class based on its parent, Document. Let's see some of these features in action.\n\nBelow is the full definition of SocialMedia for reference. Additionally, SocialMedia has been added to __init__.py for ease of use.\n\nclass SocialMedia(Document):\n    def __init__(self, text):\n        Document.__init__(self, text)\n        self.hashtag_counts = self._count_hashtags()\n        self.mention_counts = self._count_mentions()\n\n    def _count_hashtags(self):\n        # Filter attribute so only words starting with '#' remain\n        return filter_word_counts(self.word_counts, first_char='#')      \n\n    def _count_mentions(self):\n        # Filter attribute so only words starting with '@' remain\n        return filter_word_counts(self.word_counts, first_char='@')","metadata":{},"cell_type":"markdown","id":"4456b29f-2b7b-457e-b4fe-0d204f2e7cf2"},{"source":"# Import custom text_analyzer package\nimport text_analyzer\n\n# Create a SocialMedia instance with datacamp_tweets\ndc_tweets = text_analyzer.SocialMedia(text=datacamp_tweets)\n\n# Print the top five most most mentioned users\nprint(dc_tweets.mention_counts.most_common(5))\n\n# Plot the most used hashtags\ntext_analyzer.plot_counter(dc_tweets.hashtag_counts)","metadata":{},"cell_type":"code","id":"af627db9-3a08-4585-b7ae-3ebdd7b7ce2f","execution_count":null,"outputs":[]},{"source":"## Exploring with dir and help\nA new method has been added to the Document class. The method is a convenience wrapper around the plot_counter() function you wrote in an earlier exercise. In this exercise, you'll use dir() and help() to identify how to utilize the new method.","metadata":{},"cell_type":"markdown","id":"98dbb7f1-be58-4427-a28c-ddfd79be0ba2"},{"source":"# Import needed package\nimport text_analyzer\n\n# Create instance of document\nmy_doc = text_analyzer.Document(datacamp_tweets)\n\n# Run help on my_doc's plot method\nhelp(my_doc.plot_counts)\n\n# Plot the word_counts of my_doc\nmy_doc.plot_counts()\n","metadata":{},"cell_type":"code","id":"3924db23-1974-4352-9d7c-8aa1e9c46515","execution_count":null,"outputs":[]},{"source":"## Creating a grandchild class\nIn this exercise you will be using inheritance to create a Tweet class from your SocialMedia class. This new grandchild class of Document will be able to tackle Twitter specific details such as retweets.","metadata":{},"cell_type":"markdown","id":"a0902fab-d0ca-481c-a60d-374324a6e15d"},{"source":"# Define a Tweet class that inherits from SocialMedia\nclass Tweets(SocialMedia):\n    def __init__(self, text):\n        # Call parent's __init__ with super()\n        super().__init__(text)\n        # Define retweets attribute with non-public method\n        self.retweets = self._process_retweets()\n\n    def _process_retweets(self):\n        # Filter tweet text to only include retweets\n        retweet_text = filter_lines(self.text, first_chars='RT')\n        # Return retweet_text as a SocialMedia object\n        return SocialMedia(retweet_text)\n","metadata":{},"cell_type":"code","id":"d83a4ce0-bb0f-446f-8b63-4c5447ff96a0","execution_count":null,"outputs":[]},{"source":"## Using inherited methods\nYou've now defined a Tweets class that's inherited methods from both Document and SocialMedia. In this exercise, you'll use inherited methods to visualize text from both tweets and retweets.\n\nBe aware that this is real data from Twitter and as such there is always a risk that it may contain profanity or other offensive content (in this exercise, and any following exercises that also use real Twitter data).","metadata":{},"cell_type":"markdown","id":"eff96f69-38f8-423b-96ec-88d268275f2a"},{"source":"# Import needed package\nimport text_analyzer\n\n# Create instance of Tweets\nmy_tweets = text_analyzer.Tweets(datacamp_tweets)\n\n# Plot the most used hashtags in the tweets\nmy_tweets.plot_counts('hashtag_counts')\n","metadata":{},"cell_type":"code","id":"a71e321e-61a6-4dc6-897a-d74d914f6d6c","execution_count":null,"outputs":[]},{"source":"# Import needed package\nimport text_analyzer\n\n# Create instance of Tweets\nmy_tweets = text_analyzer.Tweets(datacamp_tweets)\n\n# Plot the most used hashtags in the retweets\nmy_tweets.retweets.plot_counts('hashtag_counts')\n","metadata":{},"cell_type":"code","id":"6f3a8f0a-38d9-4862-9527-5c7505fc751d","execution_count":null,"outputs":[]},{"source":"## Identifying good comments\nWe learned about what characteristics make a 'good' comment. In this exercise, you'll apply this knowledge to identify a function that utilizes comment best practices.","metadata":{},"cell_type":"markdown","id":"b00588dd-e6aa-4f7a-acc3-5d24e016c1f2"},{"source":"import re\n\ndef extract_0(text):\n    # match and extract dollar amounts from the text\n    return re.findall(r'\\$\\d+\\.\\d\\d', text)\n\ndef extract_1(text):\n    # return all matches to regex pattern\n    return re.findall(r'\\$\\d+\\.\\d\\d', text)\n\n# Print the text\nprint(text)\n\n# Print the results of the function with better commenting\nprint(extract_0(text))","metadata":{},"cell_type":"code","id":"315fa362-d7b3-406d-96f7-fd99c9f3c881","execution_count":null,"outputs":[]},{"source":"## Identifying proper docstrings\nWe covered how to write fully-fledged docstrings. Before writing one of your own, this exercise will help you practice by having you identify a properly formatted docstring.\n\nIn this exercise, you'll be using the functions goldilocks(), rapunzel(), mary(), and sleeping_beauty() which have been loaded in your environment.","metadata":{},"cell_type":"markdown","id":"0d29c41d-7029-4618-b8a8-7d7da65ad072"},{"source":"# Run the help on all 4 functions\nhelp(goldilocks)\nhelp(rapunzel)\nhelp(mary)\nhelp(sleeping_beauty)\n\n# Execute the function with most complete docstring\nresult = rapunzel()\n\n# Print the result\nprint(result)","metadata":{},"cell_type":"code","id":"1a8d7ab4-6500-4431-b0df-8e612a734c79","execution_count":null,"outputs":[]},{"source":"## Writing docstrings\nWe just learned some about the benefits of docstrings. In this exercise, you will practice writing docstrings that can be utilized by a documentation generator like Sphinx.\n\nNote that your docstring submission must match the solution exactly. If you find yourself getting it wrong several times, it may be a good idea to refresh the sample code and start over.","metadata":{},"cell_type":"markdown","id":"d992b76f-3b4e-440a-bc58-0bf8edc131f5"},{"source":"# Complete the function's docstring\ndef tokenize(text, regex=r'[a-zA-z]+'):\n  \"\"\"Split text into tokens using a regular expression\n\n  :param text: text to be tokenized\n  :param regex: regular expression used to match tokens using re.findall \n  :return: a list of resulting tokens\n\n  >>> tokenize('the rain in spain')\n  ['the', 'rain', 'in', 'spain']\n  \"\"\"\n  return re.findall(regex, text, flags=re.IGNORECASE)\n\n# Print the docstring\nhelp(tokenize)","metadata":{},"cell_type":"code","id":"7e86751e-280a-4e8d-b286-6f1ae9fa1edf","execution_count":null,"outputs":[]},{"source":"## Using good function names\nA good function name can go a long way for both user and maintainer understanding. A good function name is descriptive and describes what a function does. In this exercise, you'll choose a name for a function that will help aid in its readability when used.","metadata":{},"cell_type":"markdown","id":"ad3e6dd0-7537-42a4-8ded-c205b6a44cac"},{"source":"def hypotenuse_length(leg_a, leg_b):\n    \"\"\"Find the length of a right triangle's hypotenuse\n\n    :param leg_a: length of one leg of triangle\n    :param leg_b: length of other leg of triangle\n    :return: length of hypotenuse\n    \n    >>> hypotenuse_length(3, 4)\n    5\n    \"\"\"\n    return math.sqrt(leg_a**2 + leg_b**2)\n\n  \n# Print the length of the hypotenuse with legs 6 & 8\nprint(hypotenuse_length(6, 8))","metadata":{},"cell_type":"code","id":"a190d2c2-137b-4781-9691-a37cb3a501cf","execution_count":null,"outputs":[]},{"source":"## Using good variable names\nJust like functions, descriptive variable names can make your code much more readable. In this exercise, you'll write some code using good variable naming practices.\n\nThere's not always a clear best name for a variable. The exercise has been written to try and make a clear best choice from the provided options.","metadata":{},"cell_type":"markdown","id":"a692e1c1-fd9d-450e-8e8b-36484a3bd678"},{"source":"from statistics import mean\n\n# Sample measurements of pupil diameter in mm\npupil_diameter = [3.3, 6.8, 7.0, 5.4, 2.7]\n\n# Average pupil diameter from sample\nmean_diameter = mean(pupil_diameter)\n\nprint(mean_diameter)\n","metadata":{},"cell_type":"code","id":"22e76bc7-0683-478e-b6c7-83c9b90899d2","execution_count":null,"outputs":[]},{"source":"## Refactoring for readability\nRefactoring longer functions into smaller units can help with both readability and modularity. In this exercise, you will refactor a function into smaller units. The function you will be refactoring is shown below. Note, in the exercise, you won't be using docstrings for the sake of space; in a real application, you should include documentation!\n\ndef polygon_area(n_sides, side_len):\n    \"\"\"Find the area of a regular polygon\n\n    :param n_sides: number of sides\n    :param side_len: length of polygon sides\n    :return: area of polygon\n\n    >>> round(polygon_area(4, 5))\n    25\n    \"\"\"\n    perimeter = n_sides * side_len\n\n    apothem_denominator = 2 * math.tan(math.pi / n_sides)\n    apothem = side_len / apothem_denominator\n\n    return perimeter * apothem / 2","metadata":{},"cell_type":"markdown","id":"a36ea195-15f4-46cf-bbb2-de71fa02019f"},{"source":"def polygon_perimeter(n_sides, side_len):\n    return n_sides * side_len\n\ndef polygon_apothem(n_sides, side_len):\n    denominator = 2 * math.tan(math.pi / n_sides)\n    return side_len / denominator\n\ndef polygon_area(n_sides, side_len):\n    perimeter = polygon_perimeter(n_sides, side_len)\n    apothem = polygon_apothem(n_sides, side_len)\n\n    return perimeter * apothem / 2\n\n# Print the area of a hexagon with legs of size 10\nprint(polygon_area(n_sides=6, side_len=10))","metadata":{},"cell_type":"code","id":"95314035-33ad-4cca-94b6-1631ccea95e6","execution_count":null,"outputs":[]},{"source":"## Using doctest\nWe just learned about doctest, which, if you're writing full docstrings with examples, is a simple way to minimally test your functions. In this exercise, you'll get some hands-on practice testing and debugging with doctest.\n\nThe following have all be pre-loaded in your environment: doctest, Counter, and text_analyzer.\n\nNote that your docstring submission must match the solution exactly. If you find yourself getting it wrong several times, it may be a good idea to refresh the sample code and start over.","metadata":{},"cell_type":"markdown","id":"03f8e7dc-8b3f-4b3b-9a01-b446830ecc9d"},{"source":"def sum_counters(counters):\n    \"\"\"Aggregate collections.Counter objects by summing counts\n\n    :param counters: list/tuple of counters to sum\n    :return: aggregated counters with counts summed\n\n    >>> d1 = text_analyzer.Document('1 2 fizz 4 buzz fizz 7 8')\n    >>> d2 = text_analyzer.Document('fizz buzz 11 fizz 13 14')\n    >>> sum_counters([d1.word_counts, d2.word_counts])\n    Counter({'fizz': 4, 'buzz': 2})\n    \"\"\"\n    return sum(counters, Counter())\n\ndoctest.testmod()","metadata":{},"cell_type":"code","id":"23cf703e-4bf2-48e8-ae89-52d55fb36a26","execution_count":null,"outputs":[]},{"source":"## Documenting classes for Sphinx\nsphinx is a great tool for rendering documentation as HTML. In this exercise, you'll write a docstring for a class that can be taken advantage of by sphinx.\n\nNote that your docstring submission must match the solution exactly. If you find yourself getting it wrong several times, it may be a good idea to refresh the sample code and start over.","metadata":{},"cell_type":"markdown","id":"00e51f27-718f-481e-b3c7-f49dcba17a4b"},{"source":"from text_analyzer import Document\n\nclass SocialMedia(Document):\n    \"\"\"Analyze text data from social media\n    \n    :param text: social media text to analyze\n\n    :ivar hashtag_counts: Counter object containing counts of hashtags used in text\n    :ivar mention_counts: Counter object containing counts of @mentions used in text\n    \"\"\"\n    def __init__(self, text):\n        Document.__init__(self, text)\n        self.hashtag_counts = self._count_hashtags()\n        self.mention_counts = self._count_mentions()","metadata":{},"cell_type":"code","id":"cbc3b023-1481-4b80-b72b-153a3889dc36","execution_count":null,"outputs":[]},{"source":"","metadata":{},"cell_type":"markdown","id":"45a2823c-604f-46db-b5eb-652b435592c6"}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}